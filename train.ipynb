{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+fg1/W0lpGTWAgttvDqHn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namduhus/DenseNet/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "NMNb1SXsUgSJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sCs3CbcnUeZ-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "from DenseNet import DenseNet, densenet121,densenet169,densenet201,densenet264"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = densenet264(num_classes=100)  # DenseNet-121 생성\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BriL7b2zU63C",
        "outputId": "28361059-8dca-4e77-d2f7-060efdb8fdcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DenseNet(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (features): ModuleList(\n",
            "    (0): DenseBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (1): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (2): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (3): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (4): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (5): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): TransitionLayer(\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (2): DenseBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (1): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (2): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (3): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (4): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (5): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (6): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (7): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (8): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (9): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (10): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (11): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): TransitionLayer(\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (4): DenseBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (1): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (2): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (3): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (4): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (5): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (6): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (7): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (8): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (9): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (10): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (11): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (12): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (13): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (14): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (15): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (16): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (17): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (18): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (19): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (20): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (21): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (22): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (23): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (24): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (25): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (26): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (27): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (28): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (29): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (30): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (31): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (32): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (33): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (34): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (35): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (36): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (37): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (38): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (39): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (40): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (41): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (42): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (43): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (44): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (45): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (46): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (47): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (48): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (49): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (50): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (51): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (52): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1920, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (53): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1952, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1952, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (54): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1984, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (55): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2016, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (56): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (57): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2080, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2080, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (58): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (59): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2144, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (60): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2176, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (61): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2208, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (62): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2240, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (63): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2272, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): TransitionLayer(\n",
            "      (bn): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv): Conv2d(2304, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (6): DenseBlock(\n",
            "      (layers): ModuleList(\n",
            "        (0): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (1): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (2): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (3): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (4): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (5): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (6): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (7): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (8): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (9): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (10): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (11): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (12): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (13): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (14): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (15): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (16): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (17): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (18): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (19): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (20): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (21): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (22): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (23): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (24): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1920, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (25): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1952, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1952, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (26): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(1984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(1984, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (27): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2016, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (28): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (29): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2080, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2080, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (30): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (31): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2144, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (32): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2176, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (33): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2208, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (34): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2240, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (35): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2272, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (36): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2304, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (37): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2336, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (38): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2368, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (39): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2400, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (40): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2432, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (41): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2464, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (42): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2496, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2496, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (43): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (44): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2560, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (45): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2592, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2592, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (46): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2624, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (47): BottleneckLayer(\n",
            "          (bn1): BatchNorm2d(2656, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv1): Conv2d(2656, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bn_final): BatchNorm2d(2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc): Linear(in_features=2688, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BztgtWm-b43_",
        "outputId": "1716ac76-22c9-48ab-bc6a-cd740a70fbbd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "       BatchNorm2d-5           [-1, 64, 56, 56]             128\n",
            "            Conv2d-6          [-1, 128, 56, 56]           8,192\n",
            "       BatchNorm2d-7          [-1, 128, 56, 56]             256\n",
            "            Conv2d-8           [-1, 32, 56, 56]          36,864\n",
            "   BottleneckLayer-9           [-1, 96, 56, 56]               0\n",
            "      BatchNorm2d-10           [-1, 96, 56, 56]             192\n",
            "           Conv2d-11          [-1, 128, 56, 56]          12,288\n",
            "      BatchNorm2d-12          [-1, 128, 56, 56]             256\n",
            "           Conv2d-13           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckLayer-14          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "           Conv2d-16          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
            "           Conv2d-18           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckLayer-19          [-1, 160, 56, 56]               0\n",
            "      BatchNorm2d-20          [-1, 160, 56, 56]             320\n",
            "           Conv2d-21          [-1, 128, 56, 56]          20,480\n",
            "      BatchNorm2d-22          [-1, 128, 56, 56]             256\n",
            "           Conv2d-23           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckLayer-24          [-1, 192, 56, 56]               0\n",
            "      BatchNorm2d-25          [-1, 192, 56, 56]             384\n",
            "           Conv2d-26          [-1, 128, 56, 56]          24,576\n",
            "      BatchNorm2d-27          [-1, 128, 56, 56]             256\n",
            "           Conv2d-28           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckLayer-29          [-1, 224, 56, 56]               0\n",
            "      BatchNorm2d-30          [-1, 224, 56, 56]             448\n",
            "           Conv2d-31          [-1, 128, 56, 56]          28,672\n",
            "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
            "           Conv2d-33           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckLayer-34          [-1, 256, 56, 56]               0\n",
            "       DenseBlock-35          [-1, 256, 56, 56]               0\n",
            "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "        AvgPool2d-38          [-1, 128, 28, 28]               0\n",
            "  TransitionLayer-39          [-1, 128, 28, 28]               0\n",
            "      BatchNorm2d-40          [-1, 128, 28, 28]             256\n",
            "           Conv2d-41          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
            "           Conv2d-43           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-44          [-1, 160, 28, 28]               0\n",
            "      BatchNorm2d-45          [-1, 160, 28, 28]             320\n",
            "           Conv2d-46          [-1, 128, 28, 28]          20,480\n",
            "      BatchNorm2d-47          [-1, 128, 28, 28]             256\n",
            "           Conv2d-48           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-49          [-1, 192, 28, 28]               0\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "           Conv2d-51          [-1, 128, 28, 28]          24,576\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "           Conv2d-53           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-54          [-1, 224, 28, 28]               0\n",
            "      BatchNorm2d-55          [-1, 224, 28, 28]             448\n",
            "           Conv2d-56          [-1, 128, 28, 28]          28,672\n",
            "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
            "           Conv2d-58           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-59          [-1, 256, 28, 28]               0\n",
            "      BatchNorm2d-60          [-1, 256, 28, 28]             512\n",
            "           Conv2d-61          [-1, 128, 28, 28]          32,768\n",
            "      BatchNorm2d-62          [-1, 128, 28, 28]             256\n",
            "           Conv2d-63           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-64          [-1, 288, 28, 28]               0\n",
            "      BatchNorm2d-65          [-1, 288, 28, 28]             576\n",
            "           Conv2d-66          [-1, 128, 28, 28]          36,864\n",
            "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
            "           Conv2d-68           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-69          [-1, 320, 28, 28]               0\n",
            "      BatchNorm2d-70          [-1, 320, 28, 28]             640\n",
            "           Conv2d-71          [-1, 128, 28, 28]          40,960\n",
            "      BatchNorm2d-72          [-1, 128, 28, 28]             256\n",
            "           Conv2d-73           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-74          [-1, 352, 28, 28]               0\n",
            "      BatchNorm2d-75          [-1, 352, 28, 28]             704\n",
            "           Conv2d-76          [-1, 128, 28, 28]          45,056\n",
            "      BatchNorm2d-77          [-1, 128, 28, 28]             256\n",
            "           Conv2d-78           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-79          [-1, 384, 28, 28]               0\n",
            "      BatchNorm2d-80          [-1, 384, 28, 28]             768\n",
            "           Conv2d-81          [-1, 128, 28, 28]          49,152\n",
            "      BatchNorm2d-82          [-1, 128, 28, 28]             256\n",
            "           Conv2d-83           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-84          [-1, 416, 28, 28]               0\n",
            "      BatchNorm2d-85          [-1, 416, 28, 28]             832\n",
            "           Conv2d-86          [-1, 128, 28, 28]          53,248\n",
            "      BatchNorm2d-87          [-1, 128, 28, 28]             256\n",
            "           Conv2d-88           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-89          [-1, 448, 28, 28]               0\n",
            "      BatchNorm2d-90          [-1, 448, 28, 28]             896\n",
            "           Conv2d-91          [-1, 128, 28, 28]          57,344\n",
            "      BatchNorm2d-92          [-1, 128, 28, 28]             256\n",
            "           Conv2d-93           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-94          [-1, 480, 28, 28]               0\n",
            "      BatchNorm2d-95          [-1, 480, 28, 28]             960\n",
            "           Conv2d-96          [-1, 128, 28, 28]          61,440\n",
            "      BatchNorm2d-97          [-1, 128, 28, 28]             256\n",
            "           Conv2d-98           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckLayer-99          [-1, 512, 28, 28]               0\n",
            "      DenseBlock-100          [-1, 512, 28, 28]               0\n",
            "     BatchNorm2d-101          [-1, 512, 28, 28]           1,024\n",
            "          Conv2d-102          [-1, 256, 28, 28]         131,072\n",
            "       AvgPool2d-103          [-1, 256, 14, 14]               0\n",
            " TransitionLayer-104          [-1, 256, 14, 14]               0\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "          Conv2d-106          [-1, 128, 14, 14]          32,768\n",
            "     BatchNorm2d-107          [-1, 128, 14, 14]             256\n",
            "          Conv2d-108           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-109          [-1, 288, 14, 14]               0\n",
            "     BatchNorm2d-110          [-1, 288, 14, 14]             576\n",
            "          Conv2d-111          [-1, 128, 14, 14]          36,864\n",
            "     BatchNorm2d-112          [-1, 128, 14, 14]             256\n",
            "          Conv2d-113           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-114          [-1, 320, 14, 14]               0\n",
            "     BatchNorm2d-115          [-1, 320, 14, 14]             640\n",
            "          Conv2d-116          [-1, 128, 14, 14]          40,960\n",
            "     BatchNorm2d-117          [-1, 128, 14, 14]             256\n",
            "          Conv2d-118           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-119          [-1, 352, 14, 14]               0\n",
            "     BatchNorm2d-120          [-1, 352, 14, 14]             704\n",
            "          Conv2d-121          [-1, 128, 14, 14]          45,056\n",
            "     BatchNorm2d-122          [-1, 128, 14, 14]             256\n",
            "          Conv2d-123           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-124          [-1, 384, 14, 14]               0\n",
            "     BatchNorm2d-125          [-1, 384, 14, 14]             768\n",
            "          Conv2d-126          [-1, 128, 14, 14]          49,152\n",
            "     BatchNorm2d-127          [-1, 128, 14, 14]             256\n",
            "          Conv2d-128           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-129          [-1, 416, 14, 14]               0\n",
            "     BatchNorm2d-130          [-1, 416, 14, 14]             832\n",
            "          Conv2d-131          [-1, 128, 14, 14]          53,248\n",
            "     BatchNorm2d-132          [-1, 128, 14, 14]             256\n",
            "          Conv2d-133           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-134          [-1, 448, 14, 14]               0\n",
            "     BatchNorm2d-135          [-1, 448, 14, 14]             896\n",
            "          Conv2d-136          [-1, 128, 14, 14]          57,344\n",
            "     BatchNorm2d-137          [-1, 128, 14, 14]             256\n",
            "          Conv2d-138           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-139          [-1, 480, 14, 14]               0\n",
            "     BatchNorm2d-140          [-1, 480, 14, 14]             960\n",
            "          Conv2d-141          [-1, 128, 14, 14]          61,440\n",
            "     BatchNorm2d-142          [-1, 128, 14, 14]             256\n",
            "          Conv2d-143           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-144          [-1, 512, 14, 14]               0\n",
            "     BatchNorm2d-145          [-1, 512, 14, 14]           1,024\n",
            "          Conv2d-146          [-1, 128, 14, 14]          65,536\n",
            "     BatchNorm2d-147          [-1, 128, 14, 14]             256\n",
            "          Conv2d-148           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-149          [-1, 544, 14, 14]               0\n",
            "     BatchNorm2d-150          [-1, 544, 14, 14]           1,088\n",
            "          Conv2d-151          [-1, 128, 14, 14]          69,632\n",
            "     BatchNorm2d-152          [-1, 128, 14, 14]             256\n",
            "          Conv2d-153           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-154          [-1, 576, 14, 14]               0\n",
            "     BatchNorm2d-155          [-1, 576, 14, 14]           1,152\n",
            "          Conv2d-156          [-1, 128, 14, 14]          73,728\n",
            "     BatchNorm2d-157          [-1, 128, 14, 14]             256\n",
            "          Conv2d-158           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-159          [-1, 608, 14, 14]               0\n",
            "     BatchNorm2d-160          [-1, 608, 14, 14]           1,216\n",
            "          Conv2d-161          [-1, 128, 14, 14]          77,824\n",
            "     BatchNorm2d-162          [-1, 128, 14, 14]             256\n",
            "          Conv2d-163           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-164          [-1, 640, 14, 14]               0\n",
            "     BatchNorm2d-165          [-1, 640, 14, 14]           1,280\n",
            "          Conv2d-166          [-1, 128, 14, 14]          81,920\n",
            "     BatchNorm2d-167          [-1, 128, 14, 14]             256\n",
            "          Conv2d-168           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-169          [-1, 672, 14, 14]               0\n",
            "     BatchNorm2d-170          [-1, 672, 14, 14]           1,344\n",
            "          Conv2d-171          [-1, 128, 14, 14]          86,016\n",
            "     BatchNorm2d-172          [-1, 128, 14, 14]             256\n",
            "          Conv2d-173           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-174          [-1, 704, 14, 14]               0\n",
            "     BatchNorm2d-175          [-1, 704, 14, 14]           1,408\n",
            "          Conv2d-176          [-1, 128, 14, 14]          90,112\n",
            "     BatchNorm2d-177          [-1, 128, 14, 14]             256\n",
            "          Conv2d-178           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-179          [-1, 736, 14, 14]               0\n",
            "     BatchNorm2d-180          [-1, 736, 14, 14]           1,472\n",
            "          Conv2d-181          [-1, 128, 14, 14]          94,208\n",
            "     BatchNorm2d-182          [-1, 128, 14, 14]             256\n",
            "          Conv2d-183           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-184          [-1, 768, 14, 14]               0\n",
            "     BatchNorm2d-185          [-1, 768, 14, 14]           1,536\n",
            "          Conv2d-186          [-1, 128, 14, 14]          98,304\n",
            "     BatchNorm2d-187          [-1, 128, 14, 14]             256\n",
            "          Conv2d-188           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-189          [-1, 800, 14, 14]               0\n",
            "     BatchNorm2d-190          [-1, 800, 14, 14]           1,600\n",
            "          Conv2d-191          [-1, 128, 14, 14]         102,400\n",
            "     BatchNorm2d-192          [-1, 128, 14, 14]             256\n",
            "          Conv2d-193           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-194          [-1, 832, 14, 14]               0\n",
            "     BatchNorm2d-195          [-1, 832, 14, 14]           1,664\n",
            "          Conv2d-196          [-1, 128, 14, 14]         106,496\n",
            "     BatchNorm2d-197          [-1, 128, 14, 14]             256\n",
            "          Conv2d-198           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-199          [-1, 864, 14, 14]               0\n",
            "     BatchNorm2d-200          [-1, 864, 14, 14]           1,728\n",
            "          Conv2d-201          [-1, 128, 14, 14]         110,592\n",
            "     BatchNorm2d-202          [-1, 128, 14, 14]             256\n",
            "          Conv2d-203           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-204          [-1, 896, 14, 14]               0\n",
            "     BatchNorm2d-205          [-1, 896, 14, 14]           1,792\n",
            "          Conv2d-206          [-1, 128, 14, 14]         114,688\n",
            "     BatchNorm2d-207          [-1, 128, 14, 14]             256\n",
            "          Conv2d-208           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-209          [-1, 928, 14, 14]               0\n",
            "     BatchNorm2d-210          [-1, 928, 14, 14]           1,856\n",
            "          Conv2d-211          [-1, 128, 14, 14]         118,784\n",
            "     BatchNorm2d-212          [-1, 128, 14, 14]             256\n",
            "          Conv2d-213           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-214          [-1, 960, 14, 14]               0\n",
            "     BatchNorm2d-215          [-1, 960, 14, 14]           1,920\n",
            "          Conv2d-216          [-1, 128, 14, 14]         122,880\n",
            "     BatchNorm2d-217          [-1, 128, 14, 14]             256\n",
            "          Conv2d-218           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-219          [-1, 992, 14, 14]               0\n",
            "     BatchNorm2d-220          [-1, 992, 14, 14]           1,984\n",
            "          Conv2d-221          [-1, 128, 14, 14]         126,976\n",
            "     BatchNorm2d-222          [-1, 128, 14, 14]             256\n",
            "          Conv2d-223           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-224         [-1, 1024, 14, 14]               0\n",
            "     BatchNorm2d-225         [-1, 1024, 14, 14]           2,048\n",
            "          Conv2d-226          [-1, 128, 14, 14]         131,072\n",
            "     BatchNorm2d-227          [-1, 128, 14, 14]             256\n",
            "          Conv2d-228           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-229         [-1, 1056, 14, 14]               0\n",
            "     BatchNorm2d-230         [-1, 1056, 14, 14]           2,112\n",
            "          Conv2d-231          [-1, 128, 14, 14]         135,168\n",
            "     BatchNorm2d-232          [-1, 128, 14, 14]             256\n",
            "          Conv2d-233           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-234         [-1, 1088, 14, 14]               0\n",
            "     BatchNorm2d-235         [-1, 1088, 14, 14]           2,176\n",
            "          Conv2d-236          [-1, 128, 14, 14]         139,264\n",
            "     BatchNorm2d-237          [-1, 128, 14, 14]             256\n",
            "          Conv2d-238           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-239         [-1, 1120, 14, 14]               0\n",
            "     BatchNorm2d-240         [-1, 1120, 14, 14]           2,240\n",
            "          Conv2d-241          [-1, 128, 14, 14]         143,360\n",
            "     BatchNorm2d-242          [-1, 128, 14, 14]             256\n",
            "          Conv2d-243           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-244         [-1, 1152, 14, 14]               0\n",
            "     BatchNorm2d-245         [-1, 1152, 14, 14]           2,304\n",
            "          Conv2d-246          [-1, 128, 14, 14]         147,456\n",
            "     BatchNorm2d-247          [-1, 128, 14, 14]             256\n",
            "          Conv2d-248           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-249         [-1, 1184, 14, 14]               0\n",
            "     BatchNorm2d-250         [-1, 1184, 14, 14]           2,368\n",
            "          Conv2d-251          [-1, 128, 14, 14]         151,552\n",
            "     BatchNorm2d-252          [-1, 128, 14, 14]             256\n",
            "          Conv2d-253           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-254         [-1, 1216, 14, 14]               0\n",
            "     BatchNorm2d-255         [-1, 1216, 14, 14]           2,432\n",
            "          Conv2d-256          [-1, 128, 14, 14]         155,648\n",
            "     BatchNorm2d-257          [-1, 128, 14, 14]             256\n",
            "          Conv2d-258           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-259         [-1, 1248, 14, 14]               0\n",
            "     BatchNorm2d-260         [-1, 1248, 14, 14]           2,496\n",
            "          Conv2d-261          [-1, 128, 14, 14]         159,744\n",
            "     BatchNorm2d-262          [-1, 128, 14, 14]             256\n",
            "          Conv2d-263           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-264         [-1, 1280, 14, 14]               0\n",
            "     BatchNorm2d-265         [-1, 1280, 14, 14]           2,560\n",
            "          Conv2d-266          [-1, 128, 14, 14]         163,840\n",
            "     BatchNorm2d-267          [-1, 128, 14, 14]             256\n",
            "          Conv2d-268           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-269         [-1, 1312, 14, 14]               0\n",
            "     BatchNorm2d-270         [-1, 1312, 14, 14]           2,624\n",
            "          Conv2d-271          [-1, 128, 14, 14]         167,936\n",
            "     BatchNorm2d-272          [-1, 128, 14, 14]             256\n",
            "          Conv2d-273           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-274         [-1, 1344, 14, 14]               0\n",
            "     BatchNorm2d-275         [-1, 1344, 14, 14]           2,688\n",
            "          Conv2d-276          [-1, 128, 14, 14]         172,032\n",
            "     BatchNorm2d-277          [-1, 128, 14, 14]             256\n",
            "          Conv2d-278           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-279         [-1, 1376, 14, 14]               0\n",
            "     BatchNorm2d-280         [-1, 1376, 14, 14]           2,752\n",
            "          Conv2d-281          [-1, 128, 14, 14]         176,128\n",
            "     BatchNorm2d-282          [-1, 128, 14, 14]             256\n",
            "          Conv2d-283           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-284         [-1, 1408, 14, 14]               0\n",
            "     BatchNorm2d-285         [-1, 1408, 14, 14]           2,816\n",
            "          Conv2d-286          [-1, 128, 14, 14]         180,224\n",
            "     BatchNorm2d-287          [-1, 128, 14, 14]             256\n",
            "          Conv2d-288           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-289         [-1, 1440, 14, 14]               0\n",
            "     BatchNorm2d-290         [-1, 1440, 14, 14]           2,880\n",
            "          Conv2d-291          [-1, 128, 14, 14]         184,320\n",
            "     BatchNorm2d-292          [-1, 128, 14, 14]             256\n",
            "          Conv2d-293           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-294         [-1, 1472, 14, 14]               0\n",
            "     BatchNorm2d-295         [-1, 1472, 14, 14]           2,944\n",
            "          Conv2d-296          [-1, 128, 14, 14]         188,416\n",
            "     BatchNorm2d-297          [-1, 128, 14, 14]             256\n",
            "          Conv2d-298           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-299         [-1, 1504, 14, 14]               0\n",
            "     BatchNorm2d-300         [-1, 1504, 14, 14]           3,008\n",
            "          Conv2d-301          [-1, 128, 14, 14]         192,512\n",
            "     BatchNorm2d-302          [-1, 128, 14, 14]             256\n",
            "          Conv2d-303           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-304         [-1, 1536, 14, 14]               0\n",
            "     BatchNorm2d-305         [-1, 1536, 14, 14]           3,072\n",
            "          Conv2d-306          [-1, 128, 14, 14]         196,608\n",
            "     BatchNorm2d-307          [-1, 128, 14, 14]             256\n",
            "          Conv2d-308           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-309         [-1, 1568, 14, 14]               0\n",
            "     BatchNorm2d-310         [-1, 1568, 14, 14]           3,136\n",
            "          Conv2d-311          [-1, 128, 14, 14]         200,704\n",
            "     BatchNorm2d-312          [-1, 128, 14, 14]             256\n",
            "          Conv2d-313           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-314         [-1, 1600, 14, 14]               0\n",
            "     BatchNorm2d-315         [-1, 1600, 14, 14]           3,200\n",
            "          Conv2d-316          [-1, 128, 14, 14]         204,800\n",
            "     BatchNorm2d-317          [-1, 128, 14, 14]             256\n",
            "          Conv2d-318           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-319         [-1, 1632, 14, 14]               0\n",
            "     BatchNorm2d-320         [-1, 1632, 14, 14]           3,264\n",
            "          Conv2d-321          [-1, 128, 14, 14]         208,896\n",
            "     BatchNorm2d-322          [-1, 128, 14, 14]             256\n",
            "          Conv2d-323           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-324         [-1, 1664, 14, 14]               0\n",
            "     BatchNorm2d-325         [-1, 1664, 14, 14]           3,328\n",
            "          Conv2d-326          [-1, 128, 14, 14]         212,992\n",
            "     BatchNorm2d-327          [-1, 128, 14, 14]             256\n",
            "          Conv2d-328           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-329         [-1, 1696, 14, 14]               0\n",
            "     BatchNorm2d-330         [-1, 1696, 14, 14]           3,392\n",
            "          Conv2d-331          [-1, 128, 14, 14]         217,088\n",
            "     BatchNorm2d-332          [-1, 128, 14, 14]             256\n",
            "          Conv2d-333           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-334         [-1, 1728, 14, 14]               0\n",
            "     BatchNorm2d-335         [-1, 1728, 14, 14]           3,456\n",
            "          Conv2d-336          [-1, 128, 14, 14]         221,184\n",
            "     BatchNorm2d-337          [-1, 128, 14, 14]             256\n",
            "          Conv2d-338           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-339         [-1, 1760, 14, 14]               0\n",
            "     BatchNorm2d-340         [-1, 1760, 14, 14]           3,520\n",
            "          Conv2d-341          [-1, 128, 14, 14]         225,280\n",
            "     BatchNorm2d-342          [-1, 128, 14, 14]             256\n",
            "          Conv2d-343           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-344         [-1, 1792, 14, 14]               0\n",
            "     BatchNorm2d-345         [-1, 1792, 14, 14]           3,584\n",
            "          Conv2d-346          [-1, 128, 14, 14]         229,376\n",
            "     BatchNorm2d-347          [-1, 128, 14, 14]             256\n",
            "          Conv2d-348           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-349         [-1, 1824, 14, 14]               0\n",
            "     BatchNorm2d-350         [-1, 1824, 14, 14]           3,648\n",
            "          Conv2d-351          [-1, 128, 14, 14]         233,472\n",
            "     BatchNorm2d-352          [-1, 128, 14, 14]             256\n",
            "          Conv2d-353           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-354         [-1, 1856, 14, 14]               0\n",
            "     BatchNorm2d-355         [-1, 1856, 14, 14]           3,712\n",
            "          Conv2d-356          [-1, 128, 14, 14]         237,568\n",
            "     BatchNorm2d-357          [-1, 128, 14, 14]             256\n",
            "          Conv2d-358           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-359         [-1, 1888, 14, 14]               0\n",
            "     BatchNorm2d-360         [-1, 1888, 14, 14]           3,776\n",
            "          Conv2d-361          [-1, 128, 14, 14]         241,664\n",
            "     BatchNorm2d-362          [-1, 128, 14, 14]             256\n",
            "          Conv2d-363           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-364         [-1, 1920, 14, 14]               0\n",
            "     BatchNorm2d-365         [-1, 1920, 14, 14]           3,840\n",
            "          Conv2d-366          [-1, 128, 14, 14]         245,760\n",
            "     BatchNorm2d-367          [-1, 128, 14, 14]             256\n",
            "          Conv2d-368           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-369         [-1, 1952, 14, 14]               0\n",
            "     BatchNorm2d-370         [-1, 1952, 14, 14]           3,904\n",
            "          Conv2d-371          [-1, 128, 14, 14]         249,856\n",
            "     BatchNorm2d-372          [-1, 128, 14, 14]             256\n",
            "          Conv2d-373           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-374         [-1, 1984, 14, 14]               0\n",
            "     BatchNorm2d-375         [-1, 1984, 14, 14]           3,968\n",
            "          Conv2d-376          [-1, 128, 14, 14]         253,952\n",
            "     BatchNorm2d-377          [-1, 128, 14, 14]             256\n",
            "          Conv2d-378           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-379         [-1, 2016, 14, 14]               0\n",
            "     BatchNorm2d-380         [-1, 2016, 14, 14]           4,032\n",
            "          Conv2d-381          [-1, 128, 14, 14]         258,048\n",
            "     BatchNorm2d-382          [-1, 128, 14, 14]             256\n",
            "          Conv2d-383           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-384         [-1, 2048, 14, 14]               0\n",
            "     BatchNorm2d-385         [-1, 2048, 14, 14]           4,096\n",
            "          Conv2d-386          [-1, 128, 14, 14]         262,144\n",
            "     BatchNorm2d-387          [-1, 128, 14, 14]             256\n",
            "          Conv2d-388           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-389         [-1, 2080, 14, 14]               0\n",
            "     BatchNorm2d-390         [-1, 2080, 14, 14]           4,160\n",
            "          Conv2d-391          [-1, 128, 14, 14]         266,240\n",
            "     BatchNorm2d-392          [-1, 128, 14, 14]             256\n",
            "          Conv2d-393           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-394         [-1, 2112, 14, 14]               0\n",
            "     BatchNorm2d-395         [-1, 2112, 14, 14]           4,224\n",
            "          Conv2d-396          [-1, 128, 14, 14]         270,336\n",
            "     BatchNorm2d-397          [-1, 128, 14, 14]             256\n",
            "          Conv2d-398           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-399         [-1, 2144, 14, 14]               0\n",
            "     BatchNorm2d-400         [-1, 2144, 14, 14]           4,288\n",
            "          Conv2d-401          [-1, 128, 14, 14]         274,432\n",
            "     BatchNorm2d-402          [-1, 128, 14, 14]             256\n",
            "          Conv2d-403           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-404         [-1, 2176, 14, 14]               0\n",
            "     BatchNorm2d-405         [-1, 2176, 14, 14]           4,352\n",
            "          Conv2d-406          [-1, 128, 14, 14]         278,528\n",
            "     BatchNorm2d-407          [-1, 128, 14, 14]             256\n",
            "          Conv2d-408           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-409         [-1, 2208, 14, 14]               0\n",
            "     BatchNorm2d-410         [-1, 2208, 14, 14]           4,416\n",
            "          Conv2d-411          [-1, 128, 14, 14]         282,624\n",
            "     BatchNorm2d-412          [-1, 128, 14, 14]             256\n",
            "          Conv2d-413           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-414         [-1, 2240, 14, 14]               0\n",
            "     BatchNorm2d-415         [-1, 2240, 14, 14]           4,480\n",
            "          Conv2d-416          [-1, 128, 14, 14]         286,720\n",
            "     BatchNorm2d-417          [-1, 128, 14, 14]             256\n",
            "          Conv2d-418           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-419         [-1, 2272, 14, 14]               0\n",
            "     BatchNorm2d-420         [-1, 2272, 14, 14]           4,544\n",
            "          Conv2d-421          [-1, 128, 14, 14]         290,816\n",
            "     BatchNorm2d-422          [-1, 128, 14, 14]             256\n",
            "          Conv2d-423           [-1, 32, 14, 14]          36,864\n",
            " BottleneckLayer-424         [-1, 2304, 14, 14]               0\n",
            "      DenseBlock-425         [-1, 2304, 14, 14]               0\n",
            "     BatchNorm2d-426         [-1, 2304, 14, 14]           4,608\n",
            "          Conv2d-427         [-1, 1152, 14, 14]       2,654,208\n",
            "       AvgPool2d-428           [-1, 1152, 7, 7]               0\n",
            " TransitionLayer-429           [-1, 1152, 7, 7]               0\n",
            "     BatchNorm2d-430           [-1, 1152, 7, 7]           2,304\n",
            "          Conv2d-431            [-1, 128, 7, 7]         147,456\n",
            "     BatchNorm2d-432            [-1, 128, 7, 7]             256\n",
            "          Conv2d-433             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-434           [-1, 1184, 7, 7]               0\n",
            "     BatchNorm2d-435           [-1, 1184, 7, 7]           2,368\n",
            "          Conv2d-436            [-1, 128, 7, 7]         151,552\n",
            "     BatchNorm2d-437            [-1, 128, 7, 7]             256\n",
            "          Conv2d-438             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-439           [-1, 1216, 7, 7]               0\n",
            "     BatchNorm2d-440           [-1, 1216, 7, 7]           2,432\n",
            "          Conv2d-441            [-1, 128, 7, 7]         155,648\n",
            "     BatchNorm2d-442            [-1, 128, 7, 7]             256\n",
            "          Conv2d-443             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-444           [-1, 1248, 7, 7]               0\n",
            "     BatchNorm2d-445           [-1, 1248, 7, 7]           2,496\n",
            "          Conv2d-446            [-1, 128, 7, 7]         159,744\n",
            "     BatchNorm2d-447            [-1, 128, 7, 7]             256\n",
            "          Conv2d-448             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-449           [-1, 1280, 7, 7]               0\n",
            "     BatchNorm2d-450           [-1, 1280, 7, 7]           2,560\n",
            "          Conv2d-451            [-1, 128, 7, 7]         163,840\n",
            "     BatchNorm2d-452            [-1, 128, 7, 7]             256\n",
            "          Conv2d-453             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-454           [-1, 1312, 7, 7]               0\n",
            "     BatchNorm2d-455           [-1, 1312, 7, 7]           2,624\n",
            "          Conv2d-456            [-1, 128, 7, 7]         167,936\n",
            "     BatchNorm2d-457            [-1, 128, 7, 7]             256\n",
            "          Conv2d-458             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-459           [-1, 1344, 7, 7]               0\n",
            "     BatchNorm2d-460           [-1, 1344, 7, 7]           2,688\n",
            "          Conv2d-461            [-1, 128, 7, 7]         172,032\n",
            "     BatchNorm2d-462            [-1, 128, 7, 7]             256\n",
            "          Conv2d-463             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-464           [-1, 1376, 7, 7]               0\n",
            "     BatchNorm2d-465           [-1, 1376, 7, 7]           2,752\n",
            "          Conv2d-466            [-1, 128, 7, 7]         176,128\n",
            "     BatchNorm2d-467            [-1, 128, 7, 7]             256\n",
            "          Conv2d-468             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-469           [-1, 1408, 7, 7]               0\n",
            "     BatchNorm2d-470           [-1, 1408, 7, 7]           2,816\n",
            "          Conv2d-471            [-1, 128, 7, 7]         180,224\n",
            "     BatchNorm2d-472            [-1, 128, 7, 7]             256\n",
            "          Conv2d-473             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-474           [-1, 1440, 7, 7]               0\n",
            "     BatchNorm2d-475           [-1, 1440, 7, 7]           2,880\n",
            "          Conv2d-476            [-1, 128, 7, 7]         184,320\n",
            "     BatchNorm2d-477            [-1, 128, 7, 7]             256\n",
            "          Conv2d-478             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-479           [-1, 1472, 7, 7]               0\n",
            "     BatchNorm2d-480           [-1, 1472, 7, 7]           2,944\n",
            "          Conv2d-481            [-1, 128, 7, 7]         188,416\n",
            "     BatchNorm2d-482            [-1, 128, 7, 7]             256\n",
            "          Conv2d-483             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-484           [-1, 1504, 7, 7]               0\n",
            "     BatchNorm2d-485           [-1, 1504, 7, 7]           3,008\n",
            "          Conv2d-486            [-1, 128, 7, 7]         192,512\n",
            "     BatchNorm2d-487            [-1, 128, 7, 7]             256\n",
            "          Conv2d-488             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-489           [-1, 1536, 7, 7]               0\n",
            "     BatchNorm2d-490           [-1, 1536, 7, 7]           3,072\n",
            "          Conv2d-491            [-1, 128, 7, 7]         196,608\n",
            "     BatchNorm2d-492            [-1, 128, 7, 7]             256\n",
            "          Conv2d-493             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-494           [-1, 1568, 7, 7]               0\n",
            "     BatchNorm2d-495           [-1, 1568, 7, 7]           3,136\n",
            "          Conv2d-496            [-1, 128, 7, 7]         200,704\n",
            "     BatchNorm2d-497            [-1, 128, 7, 7]             256\n",
            "          Conv2d-498             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-499           [-1, 1600, 7, 7]               0\n",
            "     BatchNorm2d-500           [-1, 1600, 7, 7]           3,200\n",
            "          Conv2d-501            [-1, 128, 7, 7]         204,800\n",
            "     BatchNorm2d-502            [-1, 128, 7, 7]             256\n",
            "          Conv2d-503             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-504           [-1, 1632, 7, 7]               0\n",
            "     BatchNorm2d-505           [-1, 1632, 7, 7]           3,264\n",
            "          Conv2d-506            [-1, 128, 7, 7]         208,896\n",
            "     BatchNorm2d-507            [-1, 128, 7, 7]             256\n",
            "          Conv2d-508             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-509           [-1, 1664, 7, 7]               0\n",
            "     BatchNorm2d-510           [-1, 1664, 7, 7]           3,328\n",
            "          Conv2d-511            [-1, 128, 7, 7]         212,992\n",
            "     BatchNorm2d-512            [-1, 128, 7, 7]             256\n",
            "          Conv2d-513             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-514           [-1, 1696, 7, 7]               0\n",
            "     BatchNorm2d-515           [-1, 1696, 7, 7]           3,392\n",
            "          Conv2d-516            [-1, 128, 7, 7]         217,088\n",
            "     BatchNorm2d-517            [-1, 128, 7, 7]             256\n",
            "          Conv2d-518             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-519           [-1, 1728, 7, 7]               0\n",
            "     BatchNorm2d-520           [-1, 1728, 7, 7]           3,456\n",
            "          Conv2d-521            [-1, 128, 7, 7]         221,184\n",
            "     BatchNorm2d-522            [-1, 128, 7, 7]             256\n",
            "          Conv2d-523             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-524           [-1, 1760, 7, 7]               0\n",
            "     BatchNorm2d-525           [-1, 1760, 7, 7]           3,520\n",
            "          Conv2d-526            [-1, 128, 7, 7]         225,280\n",
            "     BatchNorm2d-527            [-1, 128, 7, 7]             256\n",
            "          Conv2d-528             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-529           [-1, 1792, 7, 7]               0\n",
            "     BatchNorm2d-530           [-1, 1792, 7, 7]           3,584\n",
            "          Conv2d-531            [-1, 128, 7, 7]         229,376\n",
            "     BatchNorm2d-532            [-1, 128, 7, 7]             256\n",
            "          Conv2d-533             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-534           [-1, 1824, 7, 7]               0\n",
            "     BatchNorm2d-535           [-1, 1824, 7, 7]           3,648\n",
            "          Conv2d-536            [-1, 128, 7, 7]         233,472\n",
            "     BatchNorm2d-537            [-1, 128, 7, 7]             256\n",
            "          Conv2d-538             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-539           [-1, 1856, 7, 7]               0\n",
            "     BatchNorm2d-540           [-1, 1856, 7, 7]           3,712\n",
            "          Conv2d-541            [-1, 128, 7, 7]         237,568\n",
            "     BatchNorm2d-542            [-1, 128, 7, 7]             256\n",
            "          Conv2d-543             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-544           [-1, 1888, 7, 7]               0\n",
            "     BatchNorm2d-545           [-1, 1888, 7, 7]           3,776\n",
            "          Conv2d-546            [-1, 128, 7, 7]         241,664\n",
            "     BatchNorm2d-547            [-1, 128, 7, 7]             256\n",
            "          Conv2d-548             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-549           [-1, 1920, 7, 7]               0\n",
            "     BatchNorm2d-550           [-1, 1920, 7, 7]           3,840\n",
            "          Conv2d-551            [-1, 128, 7, 7]         245,760\n",
            "     BatchNorm2d-552            [-1, 128, 7, 7]             256\n",
            "          Conv2d-553             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-554           [-1, 1952, 7, 7]               0\n",
            "     BatchNorm2d-555           [-1, 1952, 7, 7]           3,904\n",
            "          Conv2d-556            [-1, 128, 7, 7]         249,856\n",
            "     BatchNorm2d-557            [-1, 128, 7, 7]             256\n",
            "          Conv2d-558             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-559           [-1, 1984, 7, 7]               0\n",
            "     BatchNorm2d-560           [-1, 1984, 7, 7]           3,968\n",
            "          Conv2d-561            [-1, 128, 7, 7]         253,952\n",
            "     BatchNorm2d-562            [-1, 128, 7, 7]             256\n",
            "          Conv2d-563             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-564           [-1, 2016, 7, 7]               0\n",
            "     BatchNorm2d-565           [-1, 2016, 7, 7]           4,032\n",
            "          Conv2d-566            [-1, 128, 7, 7]         258,048\n",
            "     BatchNorm2d-567            [-1, 128, 7, 7]             256\n",
            "          Conv2d-568             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-569           [-1, 2048, 7, 7]               0\n",
            "     BatchNorm2d-570           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-571            [-1, 128, 7, 7]         262,144\n",
            "     BatchNorm2d-572            [-1, 128, 7, 7]             256\n",
            "          Conv2d-573             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-574           [-1, 2080, 7, 7]               0\n",
            "     BatchNorm2d-575           [-1, 2080, 7, 7]           4,160\n",
            "          Conv2d-576            [-1, 128, 7, 7]         266,240\n",
            "     BatchNorm2d-577            [-1, 128, 7, 7]             256\n",
            "          Conv2d-578             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-579           [-1, 2112, 7, 7]               0\n",
            "     BatchNorm2d-580           [-1, 2112, 7, 7]           4,224\n",
            "          Conv2d-581            [-1, 128, 7, 7]         270,336\n",
            "     BatchNorm2d-582            [-1, 128, 7, 7]             256\n",
            "          Conv2d-583             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-584           [-1, 2144, 7, 7]               0\n",
            "     BatchNorm2d-585           [-1, 2144, 7, 7]           4,288\n",
            "          Conv2d-586            [-1, 128, 7, 7]         274,432\n",
            "     BatchNorm2d-587            [-1, 128, 7, 7]             256\n",
            "          Conv2d-588             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-589           [-1, 2176, 7, 7]               0\n",
            "     BatchNorm2d-590           [-1, 2176, 7, 7]           4,352\n",
            "          Conv2d-591            [-1, 128, 7, 7]         278,528\n",
            "     BatchNorm2d-592            [-1, 128, 7, 7]             256\n",
            "          Conv2d-593             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-594           [-1, 2208, 7, 7]               0\n",
            "     BatchNorm2d-595           [-1, 2208, 7, 7]           4,416\n",
            "          Conv2d-596            [-1, 128, 7, 7]         282,624\n",
            "     BatchNorm2d-597            [-1, 128, 7, 7]             256\n",
            "          Conv2d-598             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-599           [-1, 2240, 7, 7]               0\n",
            "     BatchNorm2d-600           [-1, 2240, 7, 7]           4,480\n",
            "          Conv2d-601            [-1, 128, 7, 7]         286,720\n",
            "     BatchNorm2d-602            [-1, 128, 7, 7]             256\n",
            "          Conv2d-603             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-604           [-1, 2272, 7, 7]               0\n",
            "     BatchNorm2d-605           [-1, 2272, 7, 7]           4,544\n",
            "          Conv2d-606            [-1, 128, 7, 7]         290,816\n",
            "     BatchNorm2d-607            [-1, 128, 7, 7]             256\n",
            "          Conv2d-608             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-609           [-1, 2304, 7, 7]               0\n",
            "     BatchNorm2d-610           [-1, 2304, 7, 7]           4,608\n",
            "          Conv2d-611            [-1, 128, 7, 7]         294,912\n",
            "     BatchNorm2d-612            [-1, 128, 7, 7]             256\n",
            "          Conv2d-613             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-614           [-1, 2336, 7, 7]               0\n",
            "     BatchNorm2d-615           [-1, 2336, 7, 7]           4,672\n",
            "          Conv2d-616            [-1, 128, 7, 7]         299,008\n",
            "     BatchNorm2d-617            [-1, 128, 7, 7]             256\n",
            "          Conv2d-618             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-619           [-1, 2368, 7, 7]               0\n",
            "     BatchNorm2d-620           [-1, 2368, 7, 7]           4,736\n",
            "          Conv2d-621            [-1, 128, 7, 7]         303,104\n",
            "     BatchNorm2d-622            [-1, 128, 7, 7]             256\n",
            "          Conv2d-623             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-624           [-1, 2400, 7, 7]               0\n",
            "     BatchNorm2d-625           [-1, 2400, 7, 7]           4,800\n",
            "          Conv2d-626            [-1, 128, 7, 7]         307,200\n",
            "     BatchNorm2d-627            [-1, 128, 7, 7]             256\n",
            "          Conv2d-628             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-629           [-1, 2432, 7, 7]               0\n",
            "     BatchNorm2d-630           [-1, 2432, 7, 7]           4,864\n",
            "          Conv2d-631            [-1, 128, 7, 7]         311,296\n",
            "     BatchNorm2d-632            [-1, 128, 7, 7]             256\n",
            "          Conv2d-633             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-634           [-1, 2464, 7, 7]               0\n",
            "     BatchNorm2d-635           [-1, 2464, 7, 7]           4,928\n",
            "          Conv2d-636            [-1, 128, 7, 7]         315,392\n",
            "     BatchNorm2d-637            [-1, 128, 7, 7]             256\n",
            "          Conv2d-638             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-639           [-1, 2496, 7, 7]               0\n",
            "     BatchNorm2d-640           [-1, 2496, 7, 7]           4,992\n",
            "          Conv2d-641            [-1, 128, 7, 7]         319,488\n",
            "     BatchNorm2d-642            [-1, 128, 7, 7]             256\n",
            "          Conv2d-643             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-644           [-1, 2528, 7, 7]               0\n",
            "     BatchNorm2d-645           [-1, 2528, 7, 7]           5,056\n",
            "          Conv2d-646            [-1, 128, 7, 7]         323,584\n",
            "     BatchNorm2d-647            [-1, 128, 7, 7]             256\n",
            "          Conv2d-648             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-649           [-1, 2560, 7, 7]               0\n",
            "     BatchNorm2d-650           [-1, 2560, 7, 7]           5,120\n",
            "          Conv2d-651            [-1, 128, 7, 7]         327,680\n",
            "     BatchNorm2d-652            [-1, 128, 7, 7]             256\n",
            "          Conv2d-653             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-654           [-1, 2592, 7, 7]               0\n",
            "     BatchNorm2d-655           [-1, 2592, 7, 7]           5,184\n",
            "          Conv2d-656            [-1, 128, 7, 7]         331,776\n",
            "     BatchNorm2d-657            [-1, 128, 7, 7]             256\n",
            "          Conv2d-658             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-659           [-1, 2624, 7, 7]               0\n",
            "     BatchNorm2d-660           [-1, 2624, 7, 7]           5,248\n",
            "          Conv2d-661            [-1, 128, 7, 7]         335,872\n",
            "     BatchNorm2d-662            [-1, 128, 7, 7]             256\n",
            "          Conv2d-663             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-664           [-1, 2656, 7, 7]               0\n",
            "     BatchNorm2d-665           [-1, 2656, 7, 7]           5,312\n",
            "          Conv2d-666            [-1, 128, 7, 7]         339,968\n",
            "     BatchNorm2d-667            [-1, 128, 7, 7]             256\n",
            "          Conv2d-668             [-1, 32, 7, 7]          36,864\n",
            " BottleneckLayer-669           [-1, 2688, 7, 7]               0\n",
            "      DenseBlock-670           [-1, 2688, 7, 7]               0\n",
            "     BatchNorm2d-671           [-1, 2688, 7, 7]           5,376\n",
            "          Linear-672                  [-1, 100]         268,900\n",
            "================================================================\n",
            "Total params: 30,917,604\n",
            "Trainable params: 30,917,604\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 557.18\n",
            "Params size (MB): 117.94\n",
            "Estimated Total Size (MB): 675.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "iNmu9Fj3fD6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터셋 준비\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "skwlF_fTfFlj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTjaUiGof707",
        "outputId": "aae25afa-edc2-47e6-d4ca-c7403ea0d06e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:03<00:00, 43.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1PMv-JdgKxt",
        "outputId": "0f2214a4-c345-4628-cc9d-18663db4b521"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 생성 및 초기화\n",
        "model = densenet169(num_classes=100).to(device)"
      ],
      "metadata": {
        "id": "SZVhIytBgOpk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
      ],
      "metadata": {
        "id": "h1m4gPjGgVFz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 학습 함수\n",
        "def train_model(model, trainloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in trainloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(trainloader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "# 6. 테스트 함수\n",
        "def test_model(model, testloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    test_loss = running_loss / len(testloader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "PzsoX4Y7gzAy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 학습 및 평가\n",
        "num_epochs = 100\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train_model(model, trainloader, criterion, optimizer, device)\n",
        "    test_loss, test_accuracy = test_model(model, testloader, criterion, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev9b2Y--gzyL",
        "outputId": "e93b670c-a58d-412b-b901-b2e3b85d7566"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "Train Loss: 4.6405, Train Accuracy: 5.11%\n",
            "Test Loss: 4.1443, Test Accuracy: 7.93%\n",
            "Epoch 2/100\n",
            "Train Loss: 3.7920, Train Accuracy: 10.66%\n",
            "Test Loss: 4.0692, Test Accuracy: 13.03%\n",
            "Epoch 3/100\n",
            "Train Loss: 3.5502, Train Accuracy: 14.48%\n",
            "Test Loss: 3.3980, Test Accuracy: 17.48%\n",
            "Epoch 4/100\n",
            "Train Loss: 3.2795, Train Accuracy: 19.40%\n",
            "Test Loss: 3.1840, Test Accuracy: 22.22%\n",
            "Epoch 5/100\n",
            "Train Loss: 3.0615, Train Accuracy: 23.52%\n",
            "Test Loss: 2.9722, Test Accuracy: 25.87%\n",
            "Epoch 6/100\n",
            "Train Loss: 2.8899, Train Accuracy: 26.92%\n",
            "Test Loss: 2.8016, Test Accuracy: 28.88%\n",
            "Epoch 7/100\n",
            "Train Loss: 2.7038, Train Accuracy: 30.35%\n",
            "Test Loss: 2.6687, Test Accuracy: 31.80%\n",
            "Epoch 8/100\n",
            "Train Loss: 2.5143, Train Accuracy: 34.21%\n",
            "Test Loss: 2.5201, Test Accuracy: 35.28%\n",
            "Epoch 9/100\n",
            "Train Loss: 2.3962, Train Accuracy: 36.65%\n",
            "Test Loss: 2.3638, Test Accuracy: 38.34%\n",
            "Epoch 10/100\n",
            "Train Loss: 2.2641, Train Accuracy: 39.55%\n",
            "Test Loss: 2.3625, Test Accuracy: 38.59%\n",
            "Epoch 11/100\n",
            "Train Loss: 2.1583, Train Accuracy: 41.79%\n",
            "Test Loss: 2.2812, Test Accuracy: 40.32%\n",
            "Epoch 12/100\n",
            "Train Loss: 2.1319, Train Accuracy: 42.58%\n",
            "Test Loss: 2.3993, Test Accuracy: 37.46%\n",
            "Epoch 13/100\n",
            "Train Loss: 2.0409, Train Accuracy: 44.39%\n",
            "Test Loss: 2.1633, Test Accuracy: 43.27%\n",
            "Epoch 14/100\n",
            "Train Loss: 1.9190, Train Accuracy: 46.98%\n",
            "Test Loss: 2.1435, Test Accuracy: 43.90%\n",
            "Epoch 15/100\n",
            "Train Loss: 1.8333, Train Accuracy: 49.01%\n",
            "Test Loss: 2.0774, Test Accuracy: 44.50%\n",
            "Epoch 16/100\n",
            "Train Loss: 1.7589, Train Accuracy: 50.83%\n",
            "Test Loss: 2.1156, Test Accuracy: 44.84%\n",
            "Epoch 17/100\n",
            "Train Loss: 1.6953, Train Accuracy: 52.14%\n",
            "Test Loss: 2.1925, Test Accuracy: 43.41%\n",
            "Epoch 18/100\n",
            "Train Loss: 1.6295, Train Accuracy: 53.91%\n",
            "Test Loss: 2.1142, Test Accuracy: 45.44%\n",
            "Epoch 19/100\n",
            "Train Loss: 1.5654, Train Accuracy: 55.19%\n",
            "Test Loss: 2.0570, Test Accuracy: 46.19%\n",
            "Epoch 20/100\n",
            "Train Loss: 1.5110, Train Accuracy: 56.40%\n",
            "Test Loss: 2.0061, Test Accuracy: 48.17%\n",
            "Epoch 21/100\n",
            "Train Loss: 1.4487, Train Accuracy: 57.86%\n",
            "Test Loss: 2.0018, Test Accuracy: 48.07%\n",
            "Epoch 22/100\n",
            "Train Loss: 1.3970, Train Accuracy: 59.30%\n",
            "Test Loss: 2.0002, Test Accuracy: 48.78%\n",
            "Epoch 23/100\n",
            "Train Loss: 1.3440, Train Accuracy: 60.57%\n",
            "Test Loss: 2.0052, Test Accuracy: 48.67%\n",
            "Epoch 24/100\n",
            "Train Loss: 1.2915, Train Accuracy: 62.00%\n",
            "Test Loss: 1.9854, Test Accuracy: 49.85%\n",
            "Epoch 25/100\n",
            "Train Loss: 1.2492, Train Accuracy: 62.87%\n",
            "Test Loss: 2.0072, Test Accuracy: 49.19%\n",
            "Epoch 26/100\n",
            "Train Loss: 1.1988, Train Accuracy: 64.51%\n",
            "Test Loss: 2.0056, Test Accuracy: 49.68%\n",
            "Epoch 27/100\n",
            "Train Loss: 1.1560, Train Accuracy: 65.30%\n",
            "Test Loss: 2.1028, Test Accuracy: 48.62%\n",
            "Epoch 28/100\n",
            "Train Loss: 1.1071, Train Accuracy: 66.75%\n",
            "Test Loss: 2.0229, Test Accuracy: 50.14%\n",
            "Epoch 29/100\n",
            "Train Loss: 1.0777, Train Accuracy: 67.35%\n",
            "Test Loss: 1.9928, Test Accuracy: 51.10%\n",
            "Epoch 30/100\n",
            "Train Loss: 1.0294, Train Accuracy: 68.34%\n",
            "Test Loss: 2.0598, Test Accuracy: 50.22%\n",
            "Epoch 31/100\n",
            "Train Loss: 0.6124, Train Accuracy: 82.11%\n",
            "Test Loss: 1.7197, Test Accuracy: 56.78%\n",
            "Epoch 32/100\n",
            "Train Loss: 0.4661, Train Accuracy: 86.84%\n",
            "Test Loss: 1.7402, Test Accuracy: 57.28%\n",
            "Epoch 33/100\n",
            "Train Loss: 0.3999, Train Accuracy: 88.71%\n",
            "Test Loss: 1.7639, Test Accuracy: 57.52%\n",
            "Epoch 34/100\n",
            "Train Loss: 0.3528, Train Accuracy: 90.23%\n",
            "Test Loss: 1.8071, Test Accuracy: 57.30%\n",
            "Epoch 35/100\n",
            "Train Loss: 0.3121, Train Accuracy: 91.29%\n",
            "Test Loss: 1.8271, Test Accuracy: 57.21%\n",
            "Epoch 36/100\n",
            "Train Loss: 0.2860, Train Accuracy: 92.12%\n",
            "Test Loss: 1.8534, Test Accuracy: 57.16%\n",
            "Epoch 37/100\n",
            "Train Loss: 0.2567, Train Accuracy: 93.04%\n",
            "Test Loss: 1.8843, Test Accuracy: 57.16%\n",
            "Epoch 38/100\n",
            "Train Loss: 0.2349, Train Accuracy: 93.75%\n",
            "Test Loss: 1.9029, Test Accuracy: 57.35%\n",
            "Epoch 39/100\n",
            "Train Loss: 0.2126, Train Accuracy: 94.40%\n",
            "Test Loss: 1.9299, Test Accuracy: 56.88%\n",
            "Epoch 40/100\n",
            "Train Loss: 0.1931, Train Accuracy: 95.15%\n",
            "Test Loss: 1.9623, Test Accuracy: 56.90%\n",
            "Epoch 41/100\n",
            "Train Loss: 0.1778, Train Accuracy: 95.59%\n",
            "Test Loss: 1.9807, Test Accuracy: 56.92%\n",
            "Epoch 42/100\n",
            "Train Loss: 0.1635, Train Accuracy: 95.98%\n",
            "Test Loss: 2.0098, Test Accuracy: 56.87%\n",
            "Epoch 43/100\n",
            "Train Loss: 0.1488, Train Accuracy: 96.43%\n",
            "Test Loss: 2.0377, Test Accuracy: 56.86%\n",
            "Epoch 44/100\n",
            "Train Loss: 0.1412, Train Accuracy: 96.57%\n",
            "Test Loss: 2.0411, Test Accuracy: 56.92%\n",
            "Epoch 45/100\n",
            "Train Loss: 0.1291, Train Accuracy: 96.99%\n",
            "Test Loss: 2.0786, Test Accuracy: 56.74%\n",
            "Epoch 46/100\n",
            "Train Loss: 0.1194, Train Accuracy: 97.22%\n",
            "Test Loss: 2.0894, Test Accuracy: 57.01%\n",
            "Epoch 47/100\n",
            "Train Loss: 0.1106, Train Accuracy: 97.57%\n",
            "Test Loss: 2.1065, Test Accuracy: 57.04%\n",
            "Epoch 48/100\n",
            "Train Loss: 0.1042, Train Accuracy: 97.72%\n",
            "Test Loss: 2.1248, Test Accuracy: 56.79%\n",
            "Epoch 49/100\n",
            "Train Loss: 0.0986, Train Accuracy: 97.78%\n",
            "Test Loss: 2.1337, Test Accuracy: 56.83%\n",
            "Epoch 50/100\n",
            "Train Loss: 0.0928, Train Accuracy: 98.01%\n",
            "Test Loss: 2.1570, Test Accuracy: 56.63%\n",
            "Epoch 51/100\n",
            "Train Loss: 0.0853, Train Accuracy: 98.21%\n",
            "Test Loss: 2.1723, Test Accuracy: 56.91%\n",
            "Epoch 52/100\n",
            "Train Loss: 0.0823, Train Accuracy: 98.25%\n",
            "Test Loss: 2.1914, Test Accuracy: 56.75%\n",
            "Epoch 53/100\n",
            "Train Loss: 0.0761, Train Accuracy: 98.44%\n",
            "Test Loss: 2.2143, Test Accuracy: 56.53%\n",
            "Epoch 54/100\n",
            "Train Loss: 0.0732, Train Accuracy: 98.48%\n",
            "Test Loss: 2.2251, Test Accuracy: 56.78%\n",
            "Epoch 55/100\n",
            "Train Loss: 0.0683, Train Accuracy: 98.62%\n",
            "Test Loss: 2.2359, Test Accuracy: 56.93%\n",
            "Epoch 56/100\n",
            "Train Loss: 0.0626, Train Accuracy: 98.72%\n",
            "Test Loss: 2.2470, Test Accuracy: 56.74%\n",
            "Epoch 57/100\n",
            "Train Loss: 0.0628, Train Accuracy: 98.72%\n",
            "Test Loss: 2.2559, Test Accuracy: 56.63%\n",
            "Epoch 58/100\n",
            "Train Loss: 0.0607, Train Accuracy: 98.82%\n",
            "Test Loss: 2.2624, Test Accuracy: 56.62%\n",
            "Epoch 59/100\n",
            "Train Loss: 0.0561, Train Accuracy: 98.94%\n",
            "Test Loss: 2.2728, Test Accuracy: 56.43%\n",
            "Epoch 60/100\n",
            "Train Loss: 0.0543, Train Accuracy: 98.94%\n",
            "Test Loss: 2.2861, Test Accuracy: 56.35%\n",
            "Epoch 61/100\n",
            "Train Loss: 0.0459, Train Accuracy: 99.23%\n",
            "Test Loss: 2.2701, Test Accuracy: 56.71%\n",
            "Epoch 62/100\n",
            "Train Loss: 0.0431, Train Accuracy: 99.24%\n",
            "Test Loss: 2.2623, Test Accuracy: 56.72%\n",
            "Epoch 63/100\n",
            "Train Loss: 0.0412, Train Accuracy: 99.35%\n",
            "Test Loss: 2.2665, Test Accuracy: 56.80%\n",
            "Epoch 64/100\n",
            "Train Loss: 0.0397, Train Accuracy: 99.36%\n",
            "Test Loss: 2.2705, Test Accuracy: 56.74%\n",
            "Epoch 65/100\n",
            "Train Loss: 0.0394, Train Accuracy: 99.43%\n",
            "Test Loss: 2.2624, Test Accuracy: 56.87%\n",
            "Epoch 66/100\n",
            "Train Loss: 0.0389, Train Accuracy: 99.41%\n",
            "Test Loss: 2.2698, Test Accuracy: 56.82%\n",
            "Epoch 67/100\n",
            "Train Loss: 0.0374, Train Accuracy: 99.44%\n",
            "Test Loss: 2.2637, Test Accuracy: 56.73%\n",
            "Epoch 68/100\n",
            "Train Loss: 0.0375, Train Accuracy: 99.45%\n",
            "Test Loss: 2.2645, Test Accuracy: 56.98%\n",
            "Epoch 69/100\n",
            "Train Loss: 0.0362, Train Accuracy: 99.52%\n",
            "Test Loss: 2.2706, Test Accuracy: 56.84%\n",
            "Epoch 70/100\n",
            "Train Loss: 0.0361, Train Accuracy: 99.47%\n",
            "Test Loss: 2.2639, Test Accuracy: 56.91%\n",
            "Epoch 71/100\n",
            "Train Loss: 0.0354, Train Accuracy: 99.48%\n",
            "Test Loss: 2.2612, Test Accuracy: 56.84%\n",
            "Epoch 72/100\n",
            "Train Loss: 0.0365, Train Accuracy: 99.45%\n",
            "Test Loss: 2.2643, Test Accuracy: 56.77%\n",
            "Epoch 73/100\n",
            "Train Loss: 0.0352, Train Accuracy: 99.52%\n",
            "Test Loss: 2.2658, Test Accuracy: 57.16%\n",
            "Epoch 74/100\n",
            "Train Loss: 0.0339, Train Accuracy: 99.52%\n",
            "Test Loss: 2.2681, Test Accuracy: 56.83%\n",
            "Epoch 75/100\n",
            "Train Loss: 0.0339, Train Accuracy: 99.49%\n",
            "Test Loss: 2.2665, Test Accuracy: 57.11%\n",
            "Epoch 76/100\n",
            "Train Loss: 0.0336, Train Accuracy: 99.56%\n",
            "Test Loss: 2.2721, Test Accuracy: 56.90%\n",
            "Epoch 77/100\n",
            "Train Loss: 0.0333, Train Accuracy: 99.59%\n",
            "Test Loss: 2.2691, Test Accuracy: 56.79%\n",
            "Epoch 78/100\n",
            "Train Loss: 0.0329, Train Accuracy: 99.56%\n",
            "Test Loss: 2.2669, Test Accuracy: 56.96%\n",
            "Epoch 79/100\n",
            "Train Loss: 0.0334, Train Accuracy: 99.53%\n",
            "Test Loss: 2.2683, Test Accuracy: 57.09%\n",
            "Epoch 80/100\n",
            "Train Loss: 0.0328, Train Accuracy: 99.54%\n",
            "Test Loss: 2.2682, Test Accuracy: 57.19%\n",
            "Epoch 81/100\n",
            "Train Loss: 0.0320, Train Accuracy: 99.54%\n",
            "Test Loss: 2.2721, Test Accuracy: 57.09%\n",
            "Epoch 82/100\n",
            "Train Loss: 0.0328, Train Accuracy: 99.57%\n",
            "Test Loss: 2.2742, Test Accuracy: 57.14%\n",
            "Epoch 83/100\n",
            "Train Loss: 0.0313, Train Accuracy: 99.58%\n",
            "Test Loss: 2.2813, Test Accuracy: 56.95%\n",
            "Epoch 84/100\n",
            "Train Loss: 0.0320, Train Accuracy: 99.56%\n",
            "Test Loss: 2.2784, Test Accuracy: 57.16%\n",
            "Epoch 85/100\n",
            "Train Loss: 0.0312, Train Accuracy: 99.58%\n",
            "Test Loss: 2.2793, Test Accuracy: 56.97%\n",
            "Epoch 86/100\n",
            "Train Loss: 0.0312, Train Accuracy: 99.60%\n",
            "Test Loss: 2.2820, Test Accuracy: 56.91%\n",
            "Epoch 87/100\n",
            "Train Loss: 0.0307, Train Accuracy: 99.61%\n",
            "Test Loss: 2.2840, Test Accuracy: 56.92%\n",
            "Epoch 88/100\n",
            "Train Loss: 0.0311, Train Accuracy: 99.58%\n",
            "Test Loss: 2.2799, Test Accuracy: 56.92%\n",
            "Epoch 89/100\n",
            "Train Loss: 0.0311, Train Accuracy: 99.54%\n",
            "Test Loss: 2.2776, Test Accuracy: 57.11%\n",
            "Epoch 90/100\n",
            "Train Loss: 0.0300, Train Accuracy: 99.60%\n",
            "Test Loss: 2.2812, Test Accuracy: 57.15%\n",
            "Epoch 91/100\n",
            "Train Loss: 0.0297, Train Accuracy: 99.60%\n",
            "Test Loss: 2.2802, Test Accuracy: 57.10%\n",
            "Epoch 92/100\n",
            "Train Loss: 0.0304, Train Accuracy: 99.60%\n",
            "Test Loss: 2.2812, Test Accuracy: 57.20%\n",
            "Epoch 93/100\n",
            "Train Loss: 0.0295, Train Accuracy: 99.61%\n",
            "Test Loss: 2.2830, Test Accuracy: 56.91%\n",
            "Epoch 94/100\n",
            "Train Loss: 0.0303, Train Accuracy: 99.61%\n",
            "Test Loss: 2.2759, Test Accuracy: 57.08%\n",
            "Epoch 95/100\n",
            "Train Loss: 0.0299, Train Accuracy: 99.64%\n",
            "Test Loss: 2.2803, Test Accuracy: 56.99%\n",
            "Epoch 96/100\n",
            "Train Loss: 0.0292, Train Accuracy: 99.63%\n",
            "Test Loss: 2.2840, Test Accuracy: 57.10%\n",
            "Epoch 97/100\n",
            "Train Loss: 0.0290, Train Accuracy: 99.64%\n",
            "Test Loss: 2.2865, Test Accuracy: 57.06%\n",
            "Epoch 98/100\n",
            "Train Loss: 0.0295, Train Accuracy: 99.61%\n",
            "Test Loss: 2.2806, Test Accuracy: 56.98%\n",
            "Epoch 99/100\n",
            "Train Loss: 0.0291, Train Accuracy: 99.63%\n",
            "Test Loss: 2.2835, Test Accuracy: 57.04%\n",
            "Epoch 100/100\n",
            "Train Loss: 0.0292, Train Accuracy: 99.64%\n",
            "Test Loss: 2.2772, Test Accuracy: 56.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. 학습 결과 시각화\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(test_accuracies, label='Test Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "1uMKYPxeg1h9",
        "outputId": "7486e113-49f4-4cfa-cf3c-7c0cde4de911"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}